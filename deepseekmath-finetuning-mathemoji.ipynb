{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers==4.45.0 accelerate==0.26.0 bitsandbytes==0.43.3","metadata":{"_uuid":"a2c0f5bb-a1c5-4a49-a582-5c0af38d9eda","_cell_guid":"2c4ff440-116c-4945-9003-09a86a0481ff","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:04.125792Z","iopub.execute_input":"2025-03-13T15:02:04.126088Z","iopub.status.idle":"2025-03-13T15:02:22.376919Z","shell.execute_reply.started":"2025-03-13T15:02:04.126063Z","shell.execute_reply":"2025-03-13T15:02:22.376115Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())\nprint(torch.version.cuda)\n!pip show bitsandbytes\nimport bitsandbytes\nprint(bitsandbytes.__version__)\nimport bitsandbytes as bnb\nimport torch\nx = torch.randn(10, device=\"cuda\")\ny = bnb.functional.quantize_4bit(x)\nprint(\"Quantization worked!\")\nimport bitsandbytes.nn\nimport bitsandbytes.functional\nprint(\"Submodules imported successfully!\")","metadata":{"_uuid":"7b52c096-9010-4c50-b8ec-9223b528b00c","_cell_guid":"bcf99c3b-540d-4ddd-b064-f4f55d3a0728","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:22.377902Z","iopub.execute_input":"2025-03-13T15:02:22.378274Z","iopub.status.idle":"2025-03-13T15:02:28.906264Z","shell.execute_reply.started":"2025-03-13T15:02:22.378238Z","shell.execute_reply":"2025-03-13T15:02:28.905310Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\ntransformers.utils.is_bitsandbytes_available = lambda: True\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport os\nimport gc","metadata":{"_uuid":"5c2870fe-4f13-4823-9210-6db409165e99","_cell_guid":"e6bb05f7-6154-49c4-b44a-6bc08653dac9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:28.907189Z","iopub.execute_input":"2025-03-13T15:02:28.907790Z","iopub.status.idle":"2025-03-13T15:02:32.170108Z","shell.execute_reply.started":"2025-03-13T15:02:28.907764Z","shell.execute_reply":"2025-03-13T15:02:32.169396Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"_uuid":"88bed53d-96b7-4cc7-a2d2-f0e14d606373","_cell_guid":"dad2c730-79d2-46c8-a424-234cdabfa1d8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:32.172124Z","iopub.execute_input":"2025-03-13T15:02:32.172492Z","iopub.status.idle":"2025-03-13T15:02:32.304826Z","shell.execute_reply.started":"2025-03-13T15:02:32.172458Z","shell.execute_reply":"2025-03-13T15:02:32.303590Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)","metadata":{"_uuid":"bb001f36-3d4a-4821-b657-b67c05aaf551","_cell_guid":"9aab7398-3922-45b4-9eb0-dceac3b568e0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:32.306131Z","iopub.execute_input":"2025-03-13T15:02:32.306369Z","iopub.status.idle":"2025-03-13T15:02:32.327254Z","shell.execute_reply.started":"2025-03-13T15:02:32.306349Z","shell.execute_reply":"2025-03-13T15:02:32.326608Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define model and tokenizer\nmodel_name = \"deepseek-ai/deepseek-math-7b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"5224bd8f-eb0f-43d1-bc59-de815b1fd9bc","_cell_guid":"b6f113a4-443f-4ced-a9fb-9f9326331c13","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:32.328014Z","iopub.execute_input":"2025-03-13T15:02:32.328277Z","iopub.status.idle":"2025-03-13T15:02:33.860741Z","shell.execute_reply.started":"2025-03-13T15:02:32.328251Z","shell.execute_reply":"2025-03-13T15:02:33.859825Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set padding token if not already set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"_uuid":"9b6eb113-8f7a-4b2b-ad7d-3707685f1ef6","_cell_guid":"b13b6e43-0162-4a3a-a485-99ad297a16ea","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:33.861631Z","iopub.execute_input":"2025-03-13T15:02:33.861869Z","iopub.status.idle":"2025-03-13T15:02:33.865506Z","shell.execute_reply.started":"2025-03-13T15:02:33.861848Z","shell.execute_reply":"2025-03-13T15:02:33.864825Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)","metadata":{"_uuid":"9cab9825-f723-434c-b48e-d0ab1f865a4b","_cell_guid":"2c9d6772-4c37-4cf7-8e76-3e8ff20df508","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:02:33.866413Z","iopub.execute_input":"2025-03-13T15:02:33.866636Z","iopub.status.idle":"2025-03-13T15:03:59.511774Z","shell.execute_reply.started":"2025-03-13T15:02:33.866609Z","shell.execute_reply":"2025-03-13T15:03:59.510868Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model","metadata":{"_uuid":"c5354803-bee1-4399-969a-ca7cff032864","_cell_guid":"906ca269-c883-46e1-9964-4ece7d6300cd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:03:59.512536Z","iopub.execute_input":"2025-03-13T15:03:59.512747Z","iopub.status.idle":"2025-03-13T15:03:59.899137Z","shell.execute_reply.started":"2025-03-13T15:03:59.512722Z","shell.execute_reply":"2025-03-13T15:03:59.898523Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define LoRA configuration\nlora_config = LoraConfig(\n    r=16,  # Rank of the LoRA adaptation\n    lora_alpha=32,  # Scaling factor\n    target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers (adjust based on model architecture)\n    lora_dropout=0.05,  # Dropout for regularization\n    bias=\"none\",  # No bias in LoRA layers\n    task_type=\"CAUSAL_LM\",  # Task type for causal language modeling\n)","metadata":{"_uuid":"0dfaa34e-1869-4c81-94e1-e64ca3a64608","_cell_guid":"e94e3e53-8f78-4677-ba09-604113b50ceb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:03:59.899859Z","iopub.execute_input":"2025-03-13T15:03:59.900159Z","iopub.status.idle":"2025-03-13T15:03:59.904230Z","shell.execute_reply.started":"2025-03-13T15:03:59.900129Z","shell.execute_reply":"2025-03-13T15:03:59.903434Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()  # Verify trainable parameters","metadata":{"_uuid":"5d56d5bc-25a7-472c-b655-68dceb2a81bd","_cell_guid":"46fc7de0-6176-40e7-85d5-73fb4533f447","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:03:59.905017Z","iopub.execute_input":"2025-03-13T15:03:59.905269Z","iopub.status.idle":"2025-03-13T15:04:00.109533Z","shell.execute_reply.started":"2025-03-13T15:03:59.905238Z","shell.execute_reply":"2025-03-13T15:04:00.108818Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = [\n  {\n    \"problem\": \"üçé + üçé + üçé = 12\",\n    \"output\": \"üçé = 4 Explanation: If three apples equal 12, then each apple equals 4 as 12/3 is 4.\"\n  },\n  {\n    \"problem\": \"üçå + üçå = 10\",\n    \"output\": \"üçå = 5 Explanation: If two bananas equal 10, then each banana equals 5.\"\n  },\n  {\n    \"problem\": \"üçä √ó 3 = 15\",\n    \"output\": \"üçä = 5 Explanation: If an orange multiplied by 3 equals 15, then each orange equals 5.\"\n  },\n  {\n    \"problem\": \"üçá √∑ 2 = 6\",\n    \"output\": \"üçá = 12 Explanation : If grapes divided by 2 equals 6, then grapes equals 12.\"\n  },\n  {\n    \"problem\": \"üçì + üçì + üçì + üçì = 20\",\n    \"output\": \"üçì = 5 Explanation : If four strawberries equal 20, then each strawberry equals 5.\"\n  },\n  {\n    \"problem\": \"üçç - üçâ = 3, üçç + üçâ = 15\",\n    \"output\": \"üçç = 9, üçâ = 6 Explanation : Using the system of equations, we can solve that pineapple equals 9 and watermelon equals 6.\"\n  },\n  {\n    \"problem\": \"üçí + üçí + üçê = 16, üçê + üçê + üçí = 19\",\n    \"output\": \"üçí = 5, üçê = 6 Explanation : Solving the system of equations: 2üçí + üçê = 16 and üçí + 2üçê = 19.\"\n  },\n  {\n    \"problem\": \"3 √ó ü•ù = üçã + 3, üçã = 12\",\n    \"output\": \"ü•ù = 5 Explanation: If lemon equals 12, then 3 times kiwi equals 15, so kiwi equals 5.\"\n  },\n  {\n    \"problem\": \"ü•≠ √ó ü•≠ = 36\",\n    \"output\": \"ü•≠ = 6 Explanation : If mango squared equals 36, then mango equals 6.\"\n  },\n  {\n    \"problem\": \"üçë √∑ 4 = 3\",\n    \"output\": \"üçë = 12 Explanation: If peach divided by 4 equals 3, then peach equals 12.\"\n  },\n  {\n    \"problem\": \"ü•• + ü•• + ü•• = üçà √ó 3, üçà = 5\",\n    \"output\": \"ü•• = 5 Explanation : If melon equals 5, then melon times 3 equals 15, so three coconuts equal 15, making each coconut equal to 5.\"\n  },\n  {\n    \"problem\": \"üçè + üçê = 11, üçè - üçê = 1\",\n    \"output\": \"üçè = 6, üçê = 5 Explanation : Solving the system of equations: green apple plus pear equals 11, and green apple minus pear equals 1.\"\n  },\n  {\n    \"problem\": \"2 √ó üçã + üçä = 25, üçã = 7\",\n    \"output\": \"üçä = 11 Explanation : If lemon equals 7, then 2 times lemon equals 14, so orange equals 11.\"\n  },\n  {\n    \"problem\": \"üçâ √∑ üçá = 4, üçá = 3\",\n    \"output\": \"üçâ = 12 Explanation : If grapes equal 3 and watermelon divided by grapes equals 4, then watermelon equals 12.\"\n  },\n  {\n    \"problem\": \"(üçé + üçå) √ó 2 = 18, üçé = 4\",\n    \"output\": \"üçå = 5 Explanation : If apple equals 4, then apple plus banana equals 9, so banana equals 5.\"\n  },\n  {\n    \"problem\": \"üçì √ó üçì - üçì = 20\",\n    \"output\": \"üçì = 5 Explanation : If strawberry squared minus strawberry equals 20, then strawberry equals 5 (5¬≤ - 5 = 20).\"\n  },\n  {\n    \"problem\": \"ü•ë + ü•ë + ü•ë + ü•ë = üçç √ó 2, üçç = 10\",\n    \"output\": \"ü•ë = 5 Explanation : If pineapple equals 10, then pineapple times 2 equals 20, so four avocados equal 20, making each avocado equal to 5.\"\n  },\n  {\n    \"problem\": \"üçí + üçí = üçä + 3, üçä = 5\",\n    \"output\": \"üçí = 4 Explanation : If orange equals 5, then two cherries equal 8, so each cherry equals 4.\"\n  },\n  {\n    \"problem\": \"3 √ó (üçé - üçê) = 6, üçé = 5\",\n    \"output\": \"üçê = 3 Explanation : If apple equals 5, then apple minus pear equals 2, so pear equals 3.\"\n  },\n  {\n    \"problem\": \"üçå √∑ üçì = 3, üçì = 2\",\n    \"output\": \"üçå = 6 Explanation : If strawberry equals 2 and banana divided by strawberry equals 3, then banana equals 6.\"\n  },\n  {\n    \"problem\": \"ü•ù √ó ü•ù √ó ü•ù = 27\",\n    \"output\": \"ü•ù = 3 Explanation : If kiwi cubed equals 27, then kiwi equals 3.\"\n  },\n  {\n    \"problem\": \"üçë + üçí + üçì = 13, üçë = 5, üçí = 4\",\n    \"output\": \"üçì = 4 Explanation : If peach equals 5 and cherry equals 4, then strawberry equals 4.\"\n  },\n  {\n    \"problem\": \"üçé √ó üçå = 24, üçé = 6\",\n    \"output\": \"üçå = 4 Explanation : If apple equals 6 and apple times banana equals 24, then banana equals 4.\"\n  },\n  {\n    \"problem\": \"üçâ - üçà = üçá + 1, üçâ = 10, üçá = 3\",\n    \"output\": \"üçà = 6 Explanation : If watermelon equals 10 and grapes equal 3, then melon equals 6.\"\n  },\n  {\n    \"problem\": \"(üçä + üçã) √∑ 2 = 7, üçä = 5\",\n    \"output\": \"üçã = 9 Explanation : If orange equals 5, then orange plus lemon equals 14, so lemon equals 9.\"\n  },\n  {\n    \"problem\": \"üçç √ó 2 - ü•• = 11, üçç = 7\",\n    \"output\": \"ü•• = 3 Explanation : If pineapple equals 7, then pineapple times 2 equals 14, so coconut equals 3.\"\n  },\n  {\n    \"problem\": \"üçè + üçê + üçä = 18, üçè = üçê + 2, üçä = üçê + 1\",\n    \"output\": \"üçè = 7, üçê = 5, üçä = 6 Explanation : Solving the system of equations with the given relationships between green apple, pear, and orange.\"\n  },\n  {\n    \"problem\": \"üçå √ó (üçé - üçì) = 12, üçé = 7, üçì = 4\",\n    \"output\": \"üçå = 4 Explanation : If apple equals 7 and strawberry equals 4, then apple minus strawberry equals 3, so banana equals 4.\"\n  },\n  {\n    \"problem\": \"üçá + üçá + üçá = (üçë √ó 2) + 3, üçë = 4\",\n    \"output\": \"üçá = 5 Explanation : If peach equals 4, then peach times 2 plus 3 equals 11, so three grapes equal 15, making each grape equal to 5.\"\n  },\n  {\n    \"problem\": \"ü•≠ √∑ (üçã - üçä) = 2, üçã = 7, üçä = 3\",\n    \"output\": \"ü•≠ = 8 Explanation : If lemon equals 7 and orange equals 3, then lemon minus orange equals 4, so mango equals 8.\"\n  }\n]","metadata":{"_uuid":"d4eb61cd-52bc-457a-a414-4a03c48412d3","_cell_guid":"131a60b4-7618-4425-ba36-9bae1bb1a988","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:04:00.110306Z","iopub.execute_input":"2025-03-13T15:04:00.110578Z","iopub.status.idle":"2025-03-13T15:04:00.117708Z","shell.execute_reply.started":"2025-03-13T15:04:00.110553Z","shell.execute_reply":"2025-03-13T15:04:00.116821Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"ff0e1562-8341-4fd8-8b2b-edac9a5a1fb3","_cell_guid":"6ca90cc2-b103-44fb-81d7-b86c6f12bf27","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare dataset for training\ndef format_data(example):\n    # Format input and output as a conversation\n    messages = [\n        {\"role\": \"user\", \"content\": example[\"problem\"]},\n        {\"role\": \"assistant\", \"content\": example[\"output\"]}\n    ]\n    # Apply chat template and tokenize\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    return {\"text\": text}","metadata":{"_uuid":"496b1ce4-5468-49e8-8a11-5a1ec84d1557","_cell_guid":"4a35e8f2-8b04-4da6-8a38-cc8d3c6e3548","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:06:35.293438Z","iopub.execute_input":"2025-03-13T15:06:35.293765Z","iopub.status.idle":"2025-03-13T15:06:35.298279Z","shell.execute_reply.started":"2025-03-13T15:06:35.293734Z","shell.execute_reply":"2025-03-13T15:06:35.297366Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n# Convert list to Hugging Face Dataset\nhf_dataset = Dataset.from_list(dataset)\ntokenized_dataset = hf_dataset.map(format_data, remove_columns=[\"problem\", \"output\"])","metadata":{"_uuid":"2c8afb1a-dfda-4c60-b2ef-5a8ccbd80bbd","_cell_guid":"b76bdd32-4be1-4153-a9cb-94bcd01b37ba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:06:44.727521Z","iopub.execute_input":"2025-03-13T15:06:44.727851Z","iopub.status.idle":"2025-03-13T15:06:44.831812Z","shell.execute_reply.started":"2025-03-13T15:06:44.727823Z","shell.execute_reply":"2025-03-13T15:06:44.830919Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_tensors=\"pt\"\n    )","metadata":{"_uuid":"e18e8158-140e-4a26-9926-d278c74c528f","_cell_guid":"5269a4a2-d486-42fa-991d-b46e197de8a6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:06:46.810587Z","iopub.execute_input":"2025-03-13T15:06:46.810896Z","iopub.status.idle":"2025-03-13T15:06:46.814797Z","shell.execute_reply.started":"2025-03-13T15:06:46.810868Z","shell.execute_reply":"2025-03-13T15:06:46.813947Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.map(tokenize_function, batched=True)","metadata":{"_uuid":"b4bf90be-ea49-4083-968c-4f3d6dd7534c","_cell_guid":"b6a86f21-76cb-4adf-88c3-0ba7dc7a8037","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:06:48.689556Z","iopub.execute_input":"2025-03-13T15:06:48.689831Z","iopub.status.idle":"2025-03-13T15:06:48.807908Z","shell.execute_reply.started":"2025-03-13T15:06:48.689810Z","shell.execute_reply":"2025-03-13T15:06:48.807012Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split dataset into train and eval (90% train, 10% eval)\ntrain_test_split = tokenized_dataset.train_test_split(test_size=0.1)\ntrain_dataset = train_test_split[\"train\"]\neval_dataset = train_test_split[\"test\"]","metadata":{"_uuid":"43fbec77-d377-487c-8ecc-ba8bb91a7237","_cell_guid":"fe733055-3d7f-4749-be09-b151b4b23573","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:06:49.911006Z","iopub.execute_input":"2025-03-13T15:06:49.911397Z","iopub.status.idle":"2025-03-13T15:06:49.925844Z","shell.execute_reply.started":"2025-03-13T15:06:49.911363Z","shell.execute_reply":"2025-03-13T15:06:49.925017Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define data collator\nfrom transformers import DataCollatorForLanguageModeling\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"_uuid":"e2cdc2ab-d815-49ae-9eb5-669cb6ba07f1","_cell_guid":"1e74b8fe-be46-4829-8737-5189a906ae47","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:06:51.427353Z","iopub.execute_input":"2025-03-13T15:06:51.427638Z","iopub.status.idle":"2025-03-13T15:07:03.247207Z","shell.execute_reply.started":"2025-03-13T15:06:51.427615Z","shell.execute_reply":"2025-03-13T15:07:03.246259Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"_uuid":"ed192fb0-b136-4f76-b784-61282c2582cf","_cell_guid":"1bb76603-103b-4f0c-ac2a-1bf35b510b6c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:07:03.248360Z","iopub.execute_input":"2025-03-13T15:07:03.248974Z","iopub.status.idle":"2025-03-13T15:07:04.360765Z","shell.execute_reply.started":"2025-03-13T15:07:03.248923Z","shell.execute_reply":"2025-03-13T15:07:04.360154Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/model_output\",\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=2,  # Adjust based on GPU memory (T4x2)\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,  # Effective batch size = 2 * 4 = 8\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    fp16=True,  # Use mixed precision for T4 GPU\n    logging_dir=\"/kaggle/working/logs\",\n    logging_steps=10,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"loss\",\n    report_to=\"none\",  # Disable wandb in Kaggle\n    push_to_hub=False,\n)","metadata":{"_uuid":"8972aa87-58d1-43e3-a48e-9042d1f1a419","_cell_guid":"cfc0f9a5-e422-4a27-b482-2d7dee5461be","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:07:04.362420Z","iopub.execute_input":"2025-03-13T15:07:04.362693Z","iopub.status.idle":"2025-03-13T15:07:04.376215Z","shell.execute_reply.started":"2025-03-13T15:07:04.362673Z","shell.execute_reply":"2025-03-13T15:07:04.375291Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define compute metrics (optional, for evaluation)\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n    return {\"accuracy\": (predictions == labels).mean().item()}","metadata":{"_uuid":"4fa4e84e-fa17-40de-8f65-897037a6d126","_cell_guid":"b394bf83-1a72-4a42-9c87-70a9b72dccef","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:07:04.377433Z","iopub.execute_input":"2025-03-13T15:07:04.377737Z","iopub.status.idle":"2025-03-13T15:07:04.400049Z","shell.execute_reply.started":"2025-03-13T15:07:04.377698Z","shell.execute_reply":"2025-03-13T15:07:04.399235Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    data_collator=data_collator,\n    # compute_metrics=compute_metrics  # Uncomment if you want accuracy metrics\n)","metadata":{"_uuid":"829fbe9b-4be0-4db5-8646-1dada14ecebc","_cell_guid":"77af6ba3-c6b4-424f-bb1d-2651ffa8e93d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:07:04.400889Z","iopub.execute_input":"2025-03-13T15:07:04.401193Z","iopub.status.idle":"2025-03-13T15:07:04.451595Z","shell.execute_reply.started":"2025-03-13T15:07:04.401164Z","shell.execute_reply":"2025-03-13T15:07:04.450985Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\ntrainer.train()","metadata":{"_uuid":"8115af9a-7725-462d-b3a0-6127ea0350c6","_cell_guid":"b0d603da-a7ce-4c98-a7f5-da8f740945d1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:07:04.452210Z","iopub.execute_input":"2025-03-13T15:07:04.452453Z","iopub.status.idle":"2025-03-13T15:08:29.544399Z","shell.execute_reply.started":"2025-03-13T15:07:04.452430Z","shell.execute_reply":"2025-03-13T15:08:29.543725Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the model and tokenizer\noutput_dir = \"/kaggle/working/finetuned_model\"\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n\n# Zip the model directory for easy download (optional)\nimport shutil\nshutil.make_archive(\"/kaggle/working/finetuned_model\", \"zip\", output_dir)\nprint(\"Model and tokenizer saved and zipped at /kaggle/working/finetuned_model.zip\")\n\n# Test inference\nmessages = [\n    {\"role\": \"user\", \"content\": \"ü•≠ √∑ (üçã - üçä) = 2, üçã = 7, üçä = 3\"}\n]\ninput_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\noutputs = model.generate(input_tensor, max_new_tokens=100, pad_token_id=tokenizer.eos_token_id)\nresult = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\nprint(\"Test inference result:\", result)","metadata":{"_uuid":"292a9844-8c76-47ff-b15c-e3db847b6e2a","_cell_guid":"973e9da0-b8b8-42ec-825f-f11b3f8451ab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:34:56.049232Z","iopub.execute_input":"2025-03-13T15:34:56.049571Z","iopub.status.idle":"2025-03-13T15:35:08.335006Z","shell.execute_reply.started":"2025-03-13T15:34:56.049543Z","shell.execute_reply":"2025-03-13T15:35:08.334116Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import PeftModel","metadata":{"_uuid":"d5270921-1026-4f4e-bd8a-2f0fc427d1d0","_cell_guid":"b5e1e61c-dc8f-4b95-83fa-b224155e43d2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:35:53.800756Z","iopub.execute_input":"2025-03-13T15:35:53.801291Z","iopub.status.idle":"2025-03-13T15:35:53.805666Z","shell.execute_reply.started":"2025-03-13T15:35:53.801247Z","shell.execute_reply":"2025-03-13T15:35:53.804766Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\noutput_weights_path = \"/kaggle/working/fine_tuned_deepseek_math_weights.pth\"\ntorch.save(model.state_dict(), output_weights_path)","metadata":{"_uuid":"3f8ebb45-a911-43a2-9ff5-385e36d4ac91","_cell_guid":"6ab0c651-19de-44a9-8e41-d50a02a4ac5b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:35:54.700828Z","iopub.execute_input":"2025-03-13T15:35:54.701199Z","iopub.status.idle":"2025-03-13T15:36:05.011052Z","shell.execute_reply.started":"2025-03-13T15:35:54.701170Z","shell.execute_reply":"2025-03-13T15:36:05.010023Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gradio","metadata":{"_uuid":"3f237f70-fa1f-49b7-8239-780349baea98","_cell_guid":"6b5898a7-0f09-4d65-8d1b-1c814200aa61","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:40:29.131829Z","iopub.execute_input":"2025-03-13T15:40:29.132330Z","iopub.status.idle":"2025-03-13T15:40:39.328841Z","shell.execute_reply.started":"2025-03-13T15:40:29.132295Z","shell.execute_reply":"2025-03-13T15:40:39.327887Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gradio as gr","metadata":{"_uuid":"094f5f3f-3d0e-4a42-811d-e8278b5e11da","_cell_guid":"3d3a59d6-c5a5-4ee2-b0df-7fca463800d5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:41:57.281420Z","iopub.execute_input":"2025-03-13T15:41:57.281777Z","iopub.status.idle":"2025-03-13T15:42:00.076214Z","shell.execute_reply.started":"2025-03-13T15:41:57.281751Z","shell.execute_reply":"2025-03-13T15:42:00.075534Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_input(user_input):\n    \"\"\"Process user input through the model and return the result.\"\"\"\n    messages = [{\"role\": \"user\", \"content\": user_input}]\n    \n    # Apply chat template and generate response\n    input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(input_tensor, max_new_tokens=300, pad_token_id=tokenizer.eos_token_id)\n    result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n    \n    return result\n\n# Create Gradio interface\ndemo = gr.Interface(\n    fn=process_input,\n    inputs=gr.Textbox(placeholder=\"Enter your equation (e.g. ü•≠ √∑ (üçã - üçä) = 2, üçã = 7, üçä = 3)\"),\n    outputs=gr.Textbox(label=\"Model Output\"),\n    title=\"Emoji Math Solver\",\n    description=\"Enter a math equation with emojis, and the model will solve it.\"\n)","metadata":{"_uuid":"09ee4e1d-387a-494a-ab55-fc17ed6a98c2","_cell_guid":"b13661af-cb79-4f39-87b3-aca284a490ed","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:50:58.133820Z","iopub.execute_input":"2025-03-13T15:50:58.134197Z","iopub.status.idle":"2025-03-13T15:50:58.288722Z","shell.execute_reply.started":"2025-03-13T15:50:58.134169Z","shell.execute_reply":"2025-03-13T15:50:58.287881Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"demo.launch(share=True)","metadata":{"_uuid":"b715232d-4f7a-4312-ab05-edea4cfa3b6c","_cell_guid":"cb63312c-fdb1-4ed7-9678-cf646a6ed212","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-13T15:51:01.234366Z","iopub.execute_input":"2025-03-13T15:51:01.234670Z","iopub.status.idle":"2025-03-13T15:51:02.117879Z","shell.execute_reply.started":"2025-03-13T15:51:01.234646Z","shell.execute_reply":"2025-03-13T15:51:02.117215Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom getpass import getpass\nfrom huggingface_hub import HfApi, Repository\nimport re\n\n# Get your Hugging Face token\nhf_token = getpass(\"Enter your Hugging Face token: \")\napi = HfApi(token=hf_token)\n\n# Get your Space name (username/space-name)\nspace_name = input(\"Enter your Hugging Face Space name (username/space-name): \")\n\n# Extract the Gradio code from your notebook\n# This assumes your Gradio app is defined in a cell or cells in your notebook\nfrom IPython import get_ipython\n\n# Get all cells from the notebook\ncells = get_ipython().user_ns.get('In', [])\n\n# Extract cells that contain Gradio code\ngradio_code = []\nin_gradio_block = False\nfor cell in cells:\n    # Look for cells that import gradio or define the interface\n    if 'import gradio' in cell or 'gr.Interface' in cell or in_gradio_block:\n        in_gradio_block = True\n        gradio_code.append(cell)\n    # If we find a cell that seems to end the Gradio app definition\n    elif in_gradio_block and ('if __name__' in cell or 'demo.launch()' in cell):\n        gradio_code.append(cell)\n        in_gradio_block = False\n\n# Combine the code and ensure it has a launch method\ncombined_code = \"\\n\\n\".join(gradio_code)\n\n# Make sure the app launches when run\nif 'if __name__ == \"__main__\"' not in combined_code:\n    combined_code += '\\n\\nif __name__ == \"__main__\":\\n    demo.launch()'\n\n# Save to app.py\nwith open(\"app.py\", \"w\") as f:\n    f.write(combined_code)\n\nprint(\"Extracted Gradio code and saved to app.py\")\n\n# Clone the existing Space repository\nrepo = Repository(\n    local_dir=\"space_repo\",\n    clone_from=f\"https://huggingface.co/spaces/{space_name}\",\n    token=hf_token,\n    git_user=\"marwashahid\",\n    git_email=\"marvashahid09@gmail.com\"\n)\n\n# Copy app.py to the repository\nimport shutil\nshutil.copy(\"app.py\", \"space_repo/app.py\")\n\n# Add requirements if needed\nrequirements = \"\"\"\ngradio>=3.50.2\n\"\"\"\nwith open(\"space_repo/requirements.txt\", \"w\") as f:\n    f.write(requirements)\n\n# Commit and push changes\nrepo.git_add()\nrepo.git_commit(\"Update from Kaggle notebook\")\nrepo.git_push()\n\nprint(f\"Successfully deployed to https://huggingface.co/spaces/{space_name}\")","metadata":{"_uuid":"f6883fbc-c5a2-434f-bf3b-6fec365729f4","_cell_guid":"d2c9a40c-bea0-4a08-9754-f9db44365da8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-13T16:52:53.609140Z","iopub.execute_input":"2025-03-13T16:52:53.609481Z","iopub.status.idle":"2025-03-13T16:53:09.251404Z","shell.execute_reply.started":"2025-03-13T16:52:53.609459Z","shell.execute_reply":"2025-03-13T16:53:09.250256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}